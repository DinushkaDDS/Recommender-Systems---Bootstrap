{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix factorization for finding Hidden genres"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this, we need to look into the rating matrix again. But now comes an additional problem. The more data we have, bigger the matrix become. And therefore computations become time consuming. In order to maintain the data features while minimizing the time consumption(computation power required), we use a technique called `Dimensional reduction`. In this notebook to separate the rating matrix into smaller parts we use a mathematical technique called `Singular Value Decomposition` (SVD)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before going in to the mentioned topics, it is important to understand the basics of matrix factorization. Assume you have a matrix `R` and then we can decompose it in following form.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "__R = U.V__\r\n",
    "</center>\r\n",
    "\r\n",
    "If R has dimensions n\\*m then U will have n\\*d and V will have d\\*m dimensions. This is called `UV-Decomposition`. In recommender systems field, U is the user-feature matrix, V is the item-feature matrix and R will be the ratings matrix. The idea behind the factorization is to find values to U and V which yield their multiplication to R matrix as close as possible, in theory it is basically solving several linear equations. (ie. which satisfy the matrix multiplication.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVD (Singular Value Decomposition)\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the most common way of factorizing matrices is SVD. In SVD we construct 3 matrices namely `U`, `V* (V Transpose)` and `Σ (Sigma)`. Here U and V acts as factors while sigma acts as the regulator for the data dimensions.\r\n",
    "<pre style='color:yellow'>\r\n",
    "<center>M = UΣV*</center>\r\n",
    "\r\n",
    "- M  = Data Marix\r\n",
    "- U  = User feature matrix\r\n",
    "- Σ  = Weights diagonal matrix (eigen values matrix)\r\n",
    "- V* = Item Feature matrix\r\n",
    "</pre>\r\n",
    "To get more theoritical understanding behind SVD you can watch [videos in here.](https://www.youtube.com/watch?v=gXbThCXjZFM&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv&index=1)\r\n",
    "\r\n",
    "Instead of implementing myself, I have used the numpy implementation of the algorithm."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "movies = ['mib', 'st', 'av', 'b', 'ss', 'lm']\r\n",
    "users = ['Sara', 'Jesper', 'Therese', 'Helle', 'Pietro', 'Ekaterina']\r\n",
    "M = pd.DataFrame([\r\n",
    "                    [5.0, 3.0, 0.0, 2.0, 2.0, 2.0],\r\n",
    "                    [4.0, 3.0, 4.0, 0.0, 3.0, 3.0],\r\n",
    "                    [5.0, 2.0, 5.0, 2.0, 1.0, 1.0],\r\n",
    "                    [3.0, 5.0, 3.0, 0.0, 1.0, 1.0],\r\n",
    "                    [3.0, 3.0, 3.0, 2.0, 4.0, 5.0],\r\n",
    "                    [2.0, 3.0, 2.0, 3.0, 5.0, 5.0]],\r\n",
    "                columns=movies,\r\n",
    "                index=users)\r\n",
    "\r\n",
    "from numpy import linalg\r\n",
    "\r\n",
    "U, sigma, V_t = linalg.svd(M)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we check the output from above matrices, we will see that their multiplication does not add up to the original values exactly. But close enough to be usable. Also in the sigma matrix (eigen values sorted) we can check the amount of information given by the each of the data rows/columns in the U/V matrices.\r\n",
    "\r\n",
    "Also we can use the sigma matrix to reduce the dimensions of the matrices while retaining most of the information available on the original data. To do that we can select the most weighted values from the sigma matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def rank_k(k):\r\n",
    "    '''\r\n",
    "    Function to reduce the rank to the given level\r\n",
    "    '''\r\n",
    "    U_reduced= np.mat(U[:,:k])\r\n",
    "    Vt_reduced = np.mat(V_t[:k,:])\r\n",
    "    Sigma_reduced = np.eye(k)*sigma[:k]\r\n",
    "    return U_reduced, Sigma_reduced, Vt_reduced\r\n",
    "\r\n",
    "U_reduced, Sigma_reduced, Vt_reduced = rank_k(4)\r\n",
    "M_hat = U_reduced * Sigma_reduced * Vt_reduced\r\n",
    "\r\n",
    "print(M_hat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 4.87147087  3.11444112  0.04893344  2.23870109  1.94083799  1.920736  ]\n",
      " [ 3.49344678  3.45787572  4.19067126  0.94886084  2.61521613  2.82032378]\n",
      " [ 5.22111879  1.8034114   4.91572235  1.58969108  1.09528095  1.14205388]\n",
      " [ 3.25351113  4.77315242  2.90384191 -0.4721446   1.14157873  1.13455568]\n",
      " [ 2.93061675  3.04700483  3.03112668  2.11137004  4.29526848  4.67079756]\n",
      " [ 2.27270952  2.76664391  1.89315701  2.50473044  4.91596291  5.35161957]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "f1058ac39a4b5cc6a2d664bf07a90cc7a0b869b1d28e3e4a0289bda448411850"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}