{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## __Jaccard Distance__\r\n",
    "\r\n",
    "A technique which can be used to measure similarity between two sets.\r\n",
    "the formula for finding the Jaccard Distance is as follows.\r\n",
    "\r\n",
    "\r\n",
    "<center><image src=\"./images/Jaccard.png\" /></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def jaccard_distance(set1, set2):\r\n",
    "\r\n",
    "    set1 = set(set1)\r\n",
    "    set2 = set(set2)\r\n",
    "\r\n",
    "    intersect = len(set1.intersection(set2))\r\n",
    "    union = len(set1.union(set2))\r\n",
    "\r\n",
    "    return 1 - (intersect/union)\r\n",
    "\r\n",
    "\r\n",
    "set1 = [1,2,3,4,5]\r\n",
    "set2 = [4,5,6,7,8]\r\n",
    "\r\n",
    "jaccard_distance(set1, set2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This above implementation can be considered as the original intended implementation. But based on the context usage can be changed as below.\r\n",
    "\r\n",
    "> assume there are 2 movies A and B. </br>\r\n",
    "* A = [1, 1, 1, 0, 0, 0]\r\n",
    "* B = [1, 1, 0, 1, 0, 0]\r\n",
    ">Assume these vector columns indicating the peoples action related to those movies (like 1= buy, 0=not buy). Therefore from user behaviour perspective same value in same position of above 2 vectors indicate some form of similarity and hence we can use jaccard similarity to measure that value.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def jaccard_similarity_s(vector1, vector2):\r\n",
    "    count = 0\r\n",
    "    for i in range(len(vector1)):\r\n",
    "        if(vector1[i]==vector2[i]):\r\n",
    "            count += 1\r\n",
    "    \r\n",
    "    return count/len(vector1)\r\n",
    "\r\n",
    "A = [1, 1, 1, 0, 0, 0]\r\n",
    "B = [1, 1, 0, 1, 0, 0]\r\n",
    "\r\n",
    "jaccard_similarity_s(A, B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## __L1 and L2 norm Distances__\r\n",
    "\r\n",
    "Assume there are 2 users say X and Y. They rate 2 items on a 1-10 scale to show their preference. Now we want to check the similarity of those 2 users based on their ratings.\r\n",
    "\r\n",
    ">For an item, rating distance (difference) = |X's rating - Y's rating|\r\n",
    ">\r\n",
    ">For convience we normalize above using: 1/(distance + 1)\r\n",
    "\r\n",
    "Lets say we measured the rating distance for items based on X and Y's ratings. We can add up these distances and say that is the overall distance between 2 users since these distances reflect how similarly they rate items. This is called `Manhatten distance` or `L1-Norm Distance`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def l1_norm_distance(rating_user1, rating_user2):\r\n",
    "    '''\r\n",
    "    If possible nomalize the distance output based on the rating values.\r\n",
    "    eg: if rating max = 10 then we can return distance as \r\n",
    "       (distance/(10*len(rating_user1)))\r\n",
    "    '''\r\n",
    "\r\n",
    "    distance = 0\r\n",
    "    for i in range(len(rating_user1)):\r\n",
    "        distance += abs(rating_user1[i]-rating_user2[i])\r\n",
    "    \r\n",
    "    return distance\r\n",
    "\r\n",
    "rating_u1 = [0,0,0,0,0]\r\n",
    "rating_u2 = [0,0,0,0,0]\r\n",
    "\r\n",
    "l1_norm_distance(rating_u1, rating_u2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "L2 Norm Distance is very similar to the L1 Norm distance, except instead taking the absolute difference between rating differences we take the squared value and their summation. This is also known as `Euclidian Distance` as well."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def l2_norm_distance(rating_user1, rating_user2):\r\n",
    "    '''\r\n",
    "    If possible nomalize the distance output based on the rating values.\r\n",
    "    '''\r\n",
    "    \r\n",
    "    squred_sum = 0\r\n",
    "    for i in range(len(rating_user1)):\r\n",
    "        squred_sum += (rating_user1[i]-rating_user2[i])**2\r\n",
    "    \r\n",
    "    return squred_sum**0.5\r\n",
    "\r\n",
    "rating_u1 = [0,0,0,0,0]\r\n",
    "rating_u2 = [5,5,5,5,5]\r\n",
    "\r\n",
    "l2_norm_distance(rating_u1, rating_u2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.180339887498949"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def cosine_similarity(user_rating1, user_rating2, adjusted = False):\r\n",
    "    '''\r\n",
    "    Note that zero related calculations may be wrong.\r\n",
    "    '''\r\n",
    "    from math import sqrt\r\n",
    "\r\n",
    "    if(not adjusted):\r\n",
    "        product = 0\r\n",
    "        r1_squared = 0\r\n",
    "        r2_squared = 0\r\n",
    "\r\n",
    "        for i in range(len(user_rating1)):\r\n",
    "            product += user_rating1[i]*user_rating2[i]\r\n",
    "            r1_squared += user_rating1[i]**2\r\n",
    "            r2_squared += user_rating2[i]**2\r\n",
    "\r\n",
    "        if(product==0):\r\n",
    "            return 1.0\r\n",
    "        elif(r1_squared==0 or r2_squared==0):\r\n",
    "            return 0.0\r\n",
    "        cosine = product/((r1_squared**0.5)*(r2_squared**0.5))\r\n",
    "        return cosine\r\n",
    "\r\n",
    "    else:\r\n",
    "\r\n",
    "        from math import sqrt\r\n",
    "\r\n",
    "        user1_avg = 0\r\n",
    "        user2_avg = 0\r\n",
    "        user1_count = 0\r\n",
    "        user2_count = 0\r\n",
    "        for i in range(len(user1_ratings)):\r\n",
    "            if(user1_ratings[i]!=0):\r\n",
    "                user1_avg += user1_ratings[i]\r\n",
    "                user1_count += 1\r\n",
    "            if(user2_ratings[i]!=0):\r\n",
    "                user2_avg += user2_ratings[i]\r\n",
    "                user2_count += 1\r\n",
    "\r\n",
    "        user1_avg = user1_avg/user1_count\r\n",
    "        user2_avg = user2_avg/user2_count\r\n",
    "\r\n",
    "        normalized_rating1 = [i-user1_avg if (i!=0) else 0 for i in user1_ratings]\r\n",
    "        normalized_rating2 = [i-user2_avg if (i!=0) else 0 for i in user2_ratings]\r\n",
    "\r\n",
    "        diff1Sq = 0\r\n",
    "        diff2Sq = 0\r\n",
    "        diffMul = 0\r\n",
    "        \r\n",
    "        # Only difference in Adjusted Cosine and Pearson's similarity is in this part.\r\n",
    "        # Here we consider all the rated items regardless of whether both users have rated them.\r\n",
    "        # If one user has not rated an item, rating would be zero.\r\n",
    "        for i in range(len(user1_ratings)):\r\n",
    "            u1 = normalized_rating1[i]\r\n",
    "            u2 = normalized_rating2[i]\r\n",
    "            diff1Sq += u1**2\r\n",
    "            diff2Sq += u2**2\r\n",
    "            diffMul += u1*u2\r\n",
    "\r\n",
    "        cosine = diffMul/(sqrt(diff1Sq)*sqrt(diff2Sq))\r\n",
    "\r\n",
    "        return cosine\r\n",
    "\r\n",
    "rating_u1 = [4,5,4,0,3,3]\r\n",
    "rating_u2 = [3,3,3,2,4,5]\r\n",
    "\r\n",
    "cosine_similarity(rating_u1, rating_u2, adjusted=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.29981267559834457"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pearson's correlation coefficient\r\n",
    "\r\n",
    "Statistical measure of calculating relationship between 2 variables. Basically can determine how different each variable on average.\r\n",
    "\r\n",
    ">eg:- In rating context, if 2 user's ratings are similar correlation coefficient would be 1 while if one likes and other dislikes coefficient would be -1. 0 indicate no relationship at all.\r\n",
    "<p></p>\r\n",
    "<center><img src=\"./images/pearson_coefficient.png\"/></center>\r\n",
    "\r\n",
    "<p>\r\n",
    "But in simple terms implementation is as follows.\r\n",
    "\r\n",
    "1. Calculate the average rating per user rated items\r\n",
    "2. Normalize the ratings. (to match different user rating patterns)\r\n",
    "3. Put the results into the formula to calculate the similarity\r\n",
    "\r\n",
    "</p>\r\n",
    "\r\n",
    "\r\n",
    ">### The only difference between the adjusted cosine and Pearson’s correlation is that the Pearson function uses item set both two users have rated, while the cosine similarity function uses all rated items even if only one has rated that, setting the ratings to zero when one of the users doesn’t rated an item."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def pearson_similarity(user1_ratings, user2_ratings):\r\n",
    "    from math import sqrt\r\n",
    "\r\n",
    "    user1_avg = 0\r\n",
    "    user2_avg = 0\r\n",
    "    user1_count = 0\r\n",
    "    user2_count = 0\r\n",
    "    for i in range(len(user1_ratings)):\r\n",
    "        if(user1_ratings[i]!=0):\r\n",
    "            user1_avg += user1_ratings[i]\r\n",
    "            user1_count += 1\r\n",
    "        if(user2_ratings[i]!=0):\r\n",
    "            user2_avg += user2_ratings[i]\r\n",
    "            user2_count += 1\r\n",
    "\r\n",
    "    user1_avg = user1_avg/user1_count\r\n",
    "    user2_avg = user2_avg/user2_count\r\n",
    "\r\n",
    "    normalized_rating1 = [i-user1_avg if (i!=0) else 0 for i in user1_ratings]\r\n",
    "    normalized_rating2 = [i-user2_avg if (i!=0) else 0 for i in user2_ratings]\r\n",
    "\r\n",
    "    diff1Sq = 0\r\n",
    "    diff2Sq = 0\r\n",
    "    diffMul = 0\r\n",
    "\r\n",
    "    # Here we only consider the set which have been rated by the both users.\r\n",
    "    for i in range(len(user1_ratings)):\r\n",
    "        if(user1_ratings[i]!=0 and user2_ratings[i]!=0):\r\n",
    "            u1 = normalized_rating1[i]\r\n",
    "            u2 = normalized_rating2[i]\r\n",
    "            diff1Sq += u1**2\r\n",
    "            diff2Sq += u2**2\r\n",
    "            diffMul += u1*u2\r\n",
    "\r\n",
    "    cosine = diffMul/(sqrt(diff1Sq)*sqrt(diff2Sq))\r\n",
    "\r\n",
    "    return cosine\r\n",
    "\r\n",
    "rating_u1 = [4,5,4,0,3,3]\r\n",
    "rating_u2 = [3,3,3,2,4,5]\r\n",
    "\r\n",
    "pearson_similarity(rating_u1, rating_u2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.7606388292556647"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "f1058ac39a4b5cc6a2d664bf07a90cc7a0b869b1d28e3e4a0289bda448411850"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}